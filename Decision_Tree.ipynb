{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41002 entries, 0 to 41475\n",
      "Columns: 1885 entries, VehYear to VehBCost_?\n",
      "dtypes: bool(2), float64(11), int64(1), uint8(1871)\n",
      "memory usage: 77.3 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from data_prep import data_prep\n",
    "\n",
    "df = data_prep()\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11017    False\n",
      "30337    False\n",
      "13004    False\n",
      "3428     False\n",
      "8843     False\n",
      "33793    False\n",
      "23531    False\n",
      "33537    False\n",
      "3922     False\n",
      "40455    False\n",
      "16035    False\n",
      "9800     False\n",
      "12952    False\n",
      "37642    False\n",
      "23440    False\n",
      "15470    False\n",
      "31305    False\n",
      "6358     False\n",
      "16718    False\n",
      "37154    False\n",
      "23510    False\n",
      "18590    False\n",
      "7589     False\n",
      "12502    False\n",
      "25413    False\n",
      "17816    False\n",
      "19407    False\n",
      "32994    False\n",
      "7142     False\n",
      "8107     False\n",
      "         ...  \n",
      "36529    False\n",
      "27592    False\n",
      "19053    False\n",
      "10934    False\n",
      "2273     False\n",
      "30536    False\n",
      "17915    False\n",
      "22998    False\n",
      "20437    False\n",
      "7857     False\n",
      "925      False\n",
      "16460    False\n",
      "14223    False\n",
      "24275    False\n",
      "20914    False\n",
      "3363     False\n",
      "33158    False\n",
      "11445    False\n",
      "9890     False\n",
      "34328    False\n",
      "31221    False\n",
      "9339     False\n",
      "36500    False\n",
      "11366    False\n",
      "31110    False\n",
      "11031    False\n",
      "37174    False\n",
      "28172    False\n",
      "30547    False\n",
      "15845    False\n",
      "Name: IsBadBuy, Length: 5301, dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# target/input split\n",
    "y = df['IsBadBuy']\n",
    "X = df.drop(['IsBadBuy'],axis = 1)\n",
    "\n",
    "# setting random state\n",
    "rs = 10\n",
    "\n",
    "# Undersampling \n",
    "badBuy_indices = df[df['IsBadBuy'] == 0].index\n",
    "\n",
    "sample_size = sum(df.IsBadBuy == 1)\n",
    "\n",
    "random_indices = np.random.choice(badBuy_indices, sample_size, replace=False)\n",
    "\n",
    "Non_badBuy_sample = df.loc[random_indices]\n",
    "\n",
    "print(Non_badBuy_sample['IsBadBuy'])\n",
    "\n",
    "Badbuys = df.loc[df['IsBadBuy']==1]\n",
    "\n",
    "sample_data = Badbuys.append(Non_badBuy_sample,ignore_index=True)\n",
    "X = sample_data.drop(['IsBadBuy'],axis = 1)\n",
    "y = sample_data['IsBadBuy']\n",
    "\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.56177302734989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# simple decision tree training\n",
    "model = DecisionTreeClassifier(random_state=rs)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "\n",
    "\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.56      0.56      1590\n",
      "        True       0.56      0.56      0.56      1591\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      3181\n",
      "   macro avg       0.56      0.56      0.56      3181\n",
      "weighted avg       0.56      0.56      0.56      3181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VehOdo : 0.10028847423940246\n",
      "MMRCurrentRetailRatio : 0.08210880014858465\n",
      "MMRCurrentAuctionAveragePrice : 0.07064678391857147\n",
      "MMRAcquisitionAuctionAveragePrice : 0.06494301684484988\n",
      "MMRAcquisitionRetailAveragePrice : 0.06465306008946631\n",
      "MMRCurrentAuctionCleanPrice : 0.0631094450009982\n",
      "VehYear : 0.060835007514111486\n",
      "WarrantyCost : 0.060808088854541295\n",
      "MMRCurrentRetailCleanPrice : 0.057879665690778945\n",
      "MMRAcquisitionAuctionCleanPrice : 0.05756482163985702\n",
      "MMRAcquisitonRetailCleanPrice : 0.055714194778263754\n",
      "MMRCurrentRetailAveragePrice : 0.05203250402590111\n",
      "IsOnlineSale : 0.010735481871975308\n",
      "Transmission_AUTO : 0.002732078730954802\n",
      "VehBCost_7500 : 0.002669264608471192\n",
      "Transmission_MANUAL : 0.0022790719001501464\n",
      "VehBCost_6800 : 0.0022257501236550865\n",
      "VehBCost_4200 : 0.002037567552221229\n",
      "VehBCost_5400 : 0.0020007815579037255\n",
      "VehBCost_5700 : 0.0018099141346059125\n"
     ]
    }
   ],
   "source": [
    "#Showing Feature importance\n",
    "import numpy as np\n",
    "\n",
    "# grab feature importances from the model and feature name from the original X\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(importances)\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "# limit to 20 features\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', importances[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5e70689d989d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "from io import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# visualize\n",
    "dotfile = StringIO()\n",
    "export_graphviz(model, out_file=dotfile, feature_names=X.columns)\n",
    "graph = pydot.graph_from_dot_data(dotfile.getvalue())\n",
    "graph[0].write_png(\"tree.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6152809594394286\n",
      "Test accuracy: 0.6079849104055328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.68      0.63      1590\n",
      "        True       0.62      0.54      0.58      1591\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      3181\n",
      "   macro avg       0.61      0.61      0.61      3181\n",
      "weighted avg       0.61      0.61      0.61      3181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pre-pruning decision tree\n",
    "model = DecisionTreeClassifier(max_depth=3, random_state=rs)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VehYear : 0.7102654015581602\n",
      "MMRCurrentAuctionCleanPrice : 0.11443865338756819\n",
      "VehOdo : 0.10349084174182029\n",
      "MMRCurrentAuctionAveragePrice : 0.04596229232282906\n",
      "MMRAcquisitionAuctionAveragePrice : 0.02584281098962225\n",
      "VehBCost_3870 : 0.0\n",
      "VehBCost_3890 : 0.0\n",
      "VehBCost_3885 : 0.0\n",
      "VehBCost_3880 : 0.0\n",
      "VehBCost_38785 : 0.0\n",
      "VehBCost_3875 : 0.0\n",
      "VehBCost_3860 : 0.0\n",
      "VehBCost_3865 : 0.0\n",
      "VehBCost_3898 : 0.0\n",
      "VehBCost_3855 : 0.0\n",
      "VehBCost_3850 : 0.0\n",
      "VehBCost_3845 : 0.0\n",
      "VehBCost_3895 : 0.0\n",
      "VehBCost_3910 : 0.0\n",
      "VehBCost_3900 : 0.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'StringIO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a40ed8175e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdotfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdotfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdotfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StringIO' is not defined"
     ]
    }
   ],
   "source": [
    "# grab feature importance from the model and feature name from the original X\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(importances)\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "# limit to 20 features\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', importances[i])\n",
    "\n",
    "# visualize\n",
    "dotfile = StringIO()\n",
    "export_graphviz(model, out_file=dotfile, feature_names=X.columns)\n",
    "graph = pydot.graph_from_dot_data(dotfile.getvalue())\n",
    "graph[0].write_png(\"week3_dt_viz.png\") # saved in the following file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = []\n",
    "train_score = []\n",
    "\n",
    "# check the model performance for max depth from 2-20\n",
    "for max_depth in range(2, 21):\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=rs)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_score.append(model.score(X_test, y_test))\n",
    "    train_score.append(model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot max depth hyperparameter values vs training and test accuracy score\n",
    "plt.plot(range(2, 21), train_score, 'b', range(2,21), test_score, 'r')\n",
    "plt.xlabel('max_depth\\nBlue = training acc. Red = test acc.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.644522301576607\n",
      "Test accuracy: 0.6104998428167243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.61      0.61      1590\n",
      "        True       0.61      0.61      0.61      1591\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      3181\n",
      "   macro avg       0.61      0.61      0.61      3181\n",
      "weighted avg       0.61      0.61      0.61      3181\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 30}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(2, 7),\n",
    "          'min_samples_leaf': range(20, 60, 10)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
